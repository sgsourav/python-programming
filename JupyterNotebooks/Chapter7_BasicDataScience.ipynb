{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Programming\n",
    "\n",
    "**Chapter 7 : Basic Data Science with Python** \n",
    "\n",
    "Python is a fun language to learn, and really easy to pick up even if you are new to programming. In fact, quite often, Python is easier to pick up if you do not have any programming experience whatsoever. Python is high level programming language, targeted at students and professionals from diverse backgrounds.\n",
    "\n",
    "In this chapter, we will cover\n",
    "- Essential Libraries\n",
    "- Case Study : Linear Regression\n",
    "- Case Study : Classification\n",
    "- Case Study : Clustering\n",
    "\n",
    "**License Declaration** : Following the lead from the inspirations for this material, and the *spirit* of Python education and development, all modules of this work are licensed under the Creative Commons Attribution 3.0 Unported License. To view a copy of this license, visit http://creativecommons.org/licenses/by/3.0/.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essential Libraries\n",
    "\n",
    "Let us begin by importing the essential Python Libraries.    \n",
    "You may install any library using `conda install <library>`.    \n",
    "Most of the libraries come by default with the Anaconda platform.\n",
    "\n",
    "> NumPy : Library for Numeric Computations in Python  \n",
    "> Pandas : Library for Data Acquisition and Preparation  \n",
    "> Matplotlib : Low-level library for Data Visualization  \n",
    "> Seaborn : Higher-level library for Data Visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need the most common Python libraries for (basic) Machine Learning.      \n",
    "Scikit-Learn (`sklearn`) will be our de-facto Machine Learning library in Python.   \n",
    "\n",
    "**Linear Regression**\n",
    "> `LinearRegression` model from `sklearn.linear_model` : Our main model for Regression   \n",
    "> `mean_squared_error` metric from `sklearn.metrics` : Performance metric for Regression       \n",
    "\n",
    "**Classification Tree**\n",
    "> `DecisionTreeClassifier` model from `sklearn.tree` : Our main model for Classification   \n",
    "> `plot_tree` method from `sklearn.tree` : Function to clearly visualize a Classification Tree   \n",
    "> `confusion_matrix` metric from `sklearn.metrics` : Performance metric for Classification     \n",
    "\n",
    "**K-Means Clustering**\n",
    "> `KMeans` model from `sklearn.cluster` : Our main model for Clustering   \n",
    "\n",
    "*Common Functionality*\n",
    "> `train_test_split` method from `sklearn.model_selection` : Random Train-Test splits     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential models and functions from sklearn\n",
    "\n",
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Classification Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# K-Means Clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Common Functionality\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study : Linear Regression\n",
    "\n",
    "We use the **\"Pokemon with stats\"** dataset from Kaggle, curated by *Alberto Barradas* (https://www.kaggle.com/abcsds/pokemon).     \n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in CSV format; hence we use the `read_csv` function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV Data\n",
    "pkmndata = pd.read_csv('files/pokemonData.csv')\n",
    "pkmndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the vital statistics of the dataset using the `type` and `shape` attributes.     \n",
    "Check the variables (and their types) in the dataset using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(pkmndata))\n",
    "print(\"Data dims : \", pkmndata.shape)\n",
    "print()\n",
    "pkmndata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship between Numeric Variables\n",
    "\n",
    "Check the mutual relationship between the numeric variables using Correlation and Jointplots.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the numeric data variables\n",
    "numDF = pd.DataFrame(pkmndata[[\"Total\", \"HP\", \"Attack\", \"Defense\", \"Sp. Atk\", \"Sp. Def\", \"Speed\"]])\n",
    "\n",
    "# Correlation Matrix\n",
    "print(numDF.corr())\n",
    "\n",
    "# Heatmap of the Correlation Matrix\n",
    "f, axes = plt.subplots(1, 1, figsize=(18, 12))\n",
    "sb.heatmap(numDF.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\", annot_kws = {\"size\": 18}, cmap = \"RdBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw pairs of variables against one another\n",
    "sb.pairplot(data = numDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-Variate Regression\n",
    "\n",
    "We will start by setting up a Uni-Variate Linear Regression problem.   \n",
    "\n",
    "> Regression Model : Response = $a$ $\\times$ Predictor + $b$  \n",
    "\n",
    "Check the mutual relationship between the variables to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the problem with Predictor(s) and Response\n",
    "predictor = \"HP\"\n",
    "response = \"Total\"\n",
    "\n",
    "# 2D scatterplot of two variables to observe their relationship\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "sb.scatterplot(x = predictor, y = response, data = pkmndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Response and Predictor variables as two individual Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[response])\n",
    "X = pd.DataFrame(pkmndata[predictor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset randomly into Train and Test datasets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`LinearRegression` is a class for the regression model in `sklearn`.     \n",
    "We need to create an object of the `LinearRegression` class, as follows.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Linear Regression object\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Linear Regression model using the Train Set `X_train` and `y_train`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Linear Regression model\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have *trained* the model to fit the following formula.\n",
    "\n",
    ">  Regression Problem : Response = $a$ $\\times$ Predictor + $b$\n",
    "\n",
    "Check Intercept ($b$) and Coefficient ($a$) of the regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients of the Linear Regression line\n",
    "print('Intercept \\t b = ', linreg.intercept_)\n",
    "print('Coefficients \\t a = ', linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the response variable using the model you just trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Response on the Train Set\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "\n",
    "# Plot the Linear Regression line\n",
    "f = plt.figure(figsize=(16, 8))\n",
    "plt.scatter(X_train, y_train)\n",
    "plt.scatter(X_train, y_train_pred, color = \"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the *Goodness of Fit* on the Train and Test Sets.    \n",
    "Metrics : Explained Variance and Mean Squared Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explained Variance (R^2) on Train Set\n",
    "print(\"Explained Variance (R^2) on Train Set \\t\", linreg.score(X_train, y_train))\n",
    "\n",
    "# Mean Squared Error (MSE) on Train Set\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "print(\"Mean Squared Error (MSE) on Train Set \\t\", mean_squared_error(y_train, y_train_pred))\n",
    "\n",
    "# Mean Squared Error (MSE) on Test Set\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "print(\"Mean Squared Error (MSE) on Test Set \\t\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is quite meaningful to check the Predictions against the True values of the Response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Response for both Train and Test\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Write a generic function in Python to perform Uni-Variate Linear Regression on an input dataset and any Response-Predictor pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Variate Linear Regression\n",
    "\n",
    "Let us set up a Multi-Variate Linear Regression problem.   \n",
    "\n",
    "> Regression Model : Response = $a_1$ $\\times$ Predictor$_1$ + $a_2$ $\\times$ Predictor$_2$ + $\\cdots$ + $a_k$ $\\times$ Predictor$_k$ + $b$      \n",
    "\n",
    "Fortunately, our standard Linear Regression code works.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Predictors and Response\n",
    "response = \"Total\"\n",
    "predictors = [\"HP\", \"Attack\", \"Defense\", \"Speed\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[response])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Train a Linear Regression Model\n",
    "linreg = LinearRegression()         # create the linear regression object\n",
    "linreg.fit(X_train, y_train)        # train the linear regression model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t\", linreg.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Mean Squared Error (MSE) \\t\", mean_squared_error(y_test, y_test_pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Write a generic function in Python to perform Multi-Variate Linear Regression on an input dataset and any Response-Predictor(s) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study : Classification\n",
    "\n",
    "We use the **\"Pokemon with stats\"** dataset from Kaggle, curated by *Alberto Barradas* (https://www.kaggle.com/abcsds/pokemon).     \n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in CSV format; hence we use the `read_csv` function from Pandas.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV Data\n",
    "pkmndata = pd.read_csv('files/pokemonData.csv')\n",
    "pkmndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the vital statistics of the dataset using the `type` and `shape` attributes.     \n",
    "Check the variables (and their types) in the dataset using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(pkmndata))\n",
    "print(\"Data dims : \", pkmndata.shape)\n",
    "print()\n",
    "pkmndata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uni-Variate Classification\n",
    "\n",
    "We will start by setting up a Uni-Variate Classification problem.   \n",
    "\n",
    "> Classification Model : Response vs Predictor \n",
    "\n",
    "Check the mutual relationship between the variables to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the problem with Predictor(s) and Response\n",
    "predictor = \"HP\"\n",
    "response = \"Legendary\"\n",
    "\n",
    "# Convert the response variable to Category\n",
    "pkmndata[response] = pkmndata[response].astype(\"category\")\n",
    "\n",
    "# Boxplot of numeric variable against categorical variable\n",
    "f = plt.figure(figsize=(16, 4))\n",
    "sb.boxplot(x = predictor, y = response, data = pkmndata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the Response and Predictor variables as two individual Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[response])\n",
    "X = pd.DataFrame(pkmndata[predictor])\n",
    "\n",
    "# Convert the response to Binary\n",
    "y[response] = y[response].astype(\"bool\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset randomly into Train and Test datasets using `train_test_split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DecisionTreeClassifier` is a class for the classification model in `sklearn`.     \n",
    "We need to create an object of the `DecisionTreeClassifier` class, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier object\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Classification Tree model using the Train Set `X_train` and `y_train`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Decision Tree model\n",
    "dectree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Decision Tree model\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 12))\n",
    "\n",
    "plot_tree(dectree, \n",
    "          filled=True, \n",
    "          feature_names=X_train.columns,\n",
    "          class_names=[\"False\",\"True\"],\n",
    "          rounded = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the *Goodness of Fit* on the Train and Test Sets.    \n",
    "Metrics : Classification Accuracy and Confusion Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Write a generic function in Python to perform Uni-Variate Classification on an input dataset and any Response-Predictor pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Variate Classification\n",
    "\n",
    "Let us set up a Multi-Variate Classification problem.   \n",
    "\n",
    "> Regression Model : Response vs {Predictor$_1$, Predictor$_2$, $\\ldots$, Predictor$_k$}      \n",
    "\n",
    "Fortunately, our standard Classification code works.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the Predictors and Response\n",
    "response = \"Legendary\"\n",
    "predictors = [\"HP\", \"Attack\", \"Defense\", \"Speed\"]\n",
    "\n",
    "# Extract Response and Predictors\n",
    "y = pd.DataFrame(pkmndata[response])\n",
    "X = pd.DataFrame(pkmndata[predictors])\n",
    "\n",
    "# Convert the response to Binary\n",
    "y[response] = y[response].astype(\"bool\")\n",
    "\n",
    "# Split the Dataset into Train and Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Decision Tree using Train Data\n",
    "dectree = DecisionTreeClassifier(max_depth = 2)  # create the decision tree object\n",
    "dectree.fit(X_train, y_train)                    # train the decision tree model\n",
    "\n",
    "# Predict Response corresponding to Predictors\n",
    "y_train_pred = dectree.predict(X_train)\n",
    "y_test_pred = dectree.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_train, y_train))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Classification Accuracy \\t:\", dectree.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Plot the Confusion Matrix for Train and Test\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "sb.heatmap(confusion_matrix(y_train, y_train_pred),\n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[0])\n",
    "sb.heatmap(confusion_matrix(y_test, y_test_pred), \n",
    "           annot = True, fmt=\".0f\", annot_kws={\"size\": 18}, ax = axes[1])\n",
    "\n",
    "# Plot the Decision Tree\n",
    "f, axes = plt.subplots(1, 1, figsize=(16, 12))\n",
    "plot_tree(dectree, \n",
    "          filled=True, \n",
    "          feature_names=X_train.columns,\n",
    "          class_names=[\"False\",\"True\"],\n",
    "          rounded = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Write a generic function in Python to perform Multi-Variate Classification on an input dataset and any Response-Predictor(s) set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Case Study : Clustering\n",
    "\n",
    "We use the **\"Iris\"** dataset from within `scikit-learn`.     \n",
    "Ref : https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-dataset\n",
    "\n",
    "### Import the Dataset\n",
    "\n",
    "The dataset is in a special internal format; hence we will extract the `data` portion.  \n",
    "Immediately after importing, take a quick look at the data using the `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the internal dataset\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris(as_frame = True)\n",
    "\n",
    "# Take only the attributes\n",
    "irisData = pd.DataFrame(iris['data'])\n",
    "irisData.columns = [\"sepalLength\", \"sepalWidth\", \"petalLength\", \"petalWidth\"]\n",
    "irisData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the vital statistics of the dataset using the `type` and `shape` attributes.     \n",
    "Check the variables (and their types) in the dataset using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Data type : \", type(irisData))\n",
    "print(\"Data dims : \", irisData.shape)\n",
    "print()\n",
    "irisData.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Variate Clustering : Sepal-related Features\n",
    "\n",
    "We will start by setting up a Bi-Variate Clustering problem, using only Sepal features.      \n",
    "Extract the required variables from the dataset, and then perform Bi-Variate Clustering.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Features from the Data\n",
    "sepalData = pd.DataFrame(irisData[['sepalLength','sepalWidth']])\n",
    "                           \n",
    "# Plot the Raw Data on a 2D grid\n",
    "f = plt.figure(figsize=(16,8))\n",
    "plt.scatter(x = \"sepalLength\", y = \"sepalWidth\", data = sepalData)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic K-Means Clustering**\n",
    "\n",
    "Guess the number of clusters from the 2D plot, and perform KMeans Clustering.    \n",
    "We will use the `KMeans` clustering model from `sklearn.cluster` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans from sklearn.cluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Guess the Number of Clusters\n",
    "num_clust = 2\n",
    "\n",
    "# Create Clustering Model using KMeans\n",
    "kmeans = KMeans(n_clusters = num_clust)\n",
    "\n",
    "# Fit the Clustering Model on the Data\n",
    "kmeans.fit(sepalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use the model on the data to `predict` the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Cluster Labels\n",
    "labels = kmeans.predict(sepalData)\n",
    "\n",
    "# Append Labels to the Data\n",
    "sepalData_labeled = sepalData.copy()\n",
    "sepalData_labeled[\"Cluster\"] = pd.Categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Clusters in the Data\n",
    "f = plt.figure(figsize=(16,8))\n",
    "plt.scatter(x = \"sepalLength\", y = \"sepalWidth\", c = \"Cluster\", cmap = 'viridis', data = sepalData_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Variate Clustering : Petal-related Features\n",
    "\n",
    "We will start by setting up a Bi-Variate Clustering problem, using only Petal features.      \n",
    "Extract the required variables from the dataset, and then perform Bi-Variate Clustering.       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Features from the Data\n",
    "petalData = pd.DataFrame(irisData[['petalLength','petalWidth']])\n",
    "                           \n",
    "# Plot the Raw Data on a 2D grid\n",
    "f = plt.figure(figsize=(16,8))\n",
    "plt.scatter(x = \"petalLength\", y = \"petalWidth\", data = petalData)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic KMeans Clustering**\n",
    "\n",
    "Guess the number of clusters from the 2D plot, and perform KMeans Clustering.    \n",
    "We will use the `KMeans` clustering model from `sklearn.cluster` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KMeans from sklearn.cluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Guess the Number of Clusters\n",
    "num_clust = 2\n",
    "\n",
    "# Create Clustering Model using KMeans\n",
    "kmeans = KMeans(n_clusters = num_clust)\n",
    "\n",
    "# Fit the Clustering Model on the Data\n",
    "kmeans.fit(petalData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may use the model on the data to `predict` the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Cluster Labels\n",
    "labels = kmeans.predict(petalData)\n",
    "\n",
    "# Append Labels to the Data\n",
    "petalData_labeled = petalData.copy()\n",
    "petalData_labeled[\"Cluster\"] = pd.Categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Clusters in the Data\n",
    "f = plt.figure(figsize=(16,8))\n",
    "plt.scatter(x = \"petalLength\", y = \"petalWidth\", c = \"Cluster\", cmap = 'viridis', data = petalData_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quick Tasks\n",
    "\n",
    "- Try out Bi-Variate Clustering on the same dataset (Sepal and Petal features) using Gaussian Mixture Model (`gmm`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
